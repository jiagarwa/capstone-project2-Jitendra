{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Project: Capstone Project 2– v5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project name:** - Citi Bike– Repricing case study and Twitter Sentiment analysis for real time reputation management\n",
    "\n",
    "**Student Name:** - Jitendra Agarwal\n",
    "\n",
    "**Course:** - Springboard cohort Jan2 2018\n",
    "\n",
    "**Summary:** - \tCiti Bike is the largest bike share program in us, with 10,000 bikes and 600 stations across \n",
    "Manhattan, Brooklyn, Queens and Jersey City. It was designed for quick trips with convenience in mind, and it’s a fun and affordable way to get around town. Everyone knows that bike sharing is the answer to many environmental and urban transportation issues, yet it’s not mainstream in US. \n",
    "I am being asked by the senior executive team at Citi bike to use data science techniques to recommend 3 key action item to increase the company’s’ business. \n",
    "\n",
    "**Problem Statement: - **\n",
    "    • Citi bike management is curious to know if there is any statistical way to find the reason in decline in trips observed few times last quarter. \n",
    "    • How are user sentiments about a recent change in pricing and if Citi bike is really useful for users from time, cost and efficiency point of view compared to other transportation options? \n",
    "    • How is the performance of unit economics per trip or per bike or per station? o What is the most common use of Citi bike? \n",
    "    • What measure can be taken to increase user trips by 5% with existing users. \n",
    "\n",
    "**Project Goals: ** -\n",
    "    • User Sentiment analysis from twitter and identify most common customer issues and how to address them. \n",
    "    • Analyze if any of the current plan can be repriced to get 5% increase on revenue with no customer impact. \n",
    "    • Can we predict a right number of bike to stationed as a station? o Propose a new monthly pass pricing for office commuters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Pre Processing and Data Wrangling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 . **Reading, accessing and filtering the Data** **\n",
    "\n",
    " Data Pre Processing and Data Wrangling\n",
    "\n",
    "    •\tRead Data from csv\n",
    "    \n",
    "    •\tDivide data in 2 part of monthly subscriber and Day pass holder\n",
    "    \n",
    "    •\tConvert birth year to Int and calculate user age\n",
    "    \n",
    "    •\tFilter data for user age > 100 as an outlier\n",
    "    \n",
    "    •\tRename columns to remove spaces from their name\n",
    "    \n",
    "    •\tAdd a unique trip id column for each row as a unique key.\n",
    "    \n",
    "    •\tExtract Date and hour from timestamp column\n",
    "    \n",
    "    •\tDetermine if a trip is Free or paid, and calculate paid units and paid amount for each trip\n",
    "    \n",
    "    •\tCreate a new DF with unique list of station list\n",
    "    \n",
    "    •\tDrop column which are not needed to reduce DF size\n",
    "    \n",
    "    •\tGet Weather data from csv and store in Data Frame.\n",
    "    \n",
    "    •\tCalculate Monthly unit metrics such as\n",
    "        o\tTotal distance\n",
    "        o\tAverage distance per trip\n",
    "        o\tAverage time per trip\n",
    "        o\tAverage distance per bike\n",
    "        o\tAverage time per bike\n",
    "        o\tAverage trip per bike\n",
    "        o\tAverage Revenue per bike\n",
    "        o\tAverage revenue per trip\n",
    "    \n",
    "    •\tCalculate monthly revenue by different streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Pandas and read csv into a DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def filter_csv_to_df(filename, filters, chunk):\n",
    "    \n",
    "    df_new=pd.DataFrame()\n",
    "\n",
    "    if chunk <= 10000 or chunk >= 100000000:\n",
    "        chunk = 10 ** 8\n",
    "        \n",
    "    for data in pd.read_csv(filename, chunksize=chunk, low_memory=False):\n",
    "        df = pd.DataFrame(data)\n",
    "        df_new = pd.concat([df_new, df], axis=0)\n",
    "        \n",
    "        if filters == 'N':\n",
    "            filter_df = df_new.loc[df_new['usertype'] != 'Subscriber']\n",
    "        else:\n",
    "            filter_df = df_new.loc[df_new['usertype'] == 'Subscriber']\n",
    "            \n",
    "    return filter_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import math \n",
    "from math import sin, cos, sqrt, atan2\n",
    "\n",
    "def mile_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a)) \n",
    "    km = 6371 * c\n",
    "    miles = km * 0.621371 * 1.414\n",
    "    if miles > 5.5 :\n",
    "        score = 0\n",
    "    else :\n",
    "        score = 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92 entries, 0 to 91\n",
      "Data columns (total 7 columns):\n",
      "Date              92 non-null object\n",
      "Trips             92 non-null int64\n",
      "Miles             92 non-null int64\n",
      "Members           92 non-null int64\n",
      "24-Hour-Passes    92 non-null int64\n",
      "3-Day-Passes      92 non-null int64\n",
      "startdate         92 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 5.1+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jitendra_agarwal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jitendra_agarwal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jitendra_agarwal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Get Weather Data and  Cleanup to get daily minimum and average temperature for each day of Q4.\n",
    "# Get summary data provided by Citibike on no of subscriber and daily pass purchases.\n",
    "\n",
    "df_LMT = pd.DataFrame(pd.read_csv('../data/LMT_Q42017.csv'))\n",
    "df_AVGT = pd.DataFrame(pd.read_csv('../data/AVGT_Q42017.csv'))\n",
    "df_summ = pd.DataFrame(pd.read_csv('../data/2017Q4-summary.csv'))\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "df1 = pd.concat([df1, df_LMT['Oct'], df_LMT['Nov'], df_LMT['Dec']], axis=0)\n",
    "df1 = df1.rename(index=str, columns={0: 'LMT'})\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "df2 = pd.concat([df2, df_AVGT['Oct'], df_AVGT['Nov'], df_AVGT['Dec']], axis=0)\n",
    "df2 = df2.rename(index=str, columns={0: 'AVGT'})\n",
    "\n",
    "df= pd.concat([df1, df2], axis=1)\n",
    "df.insert(0, 'id', range(1, 1 + len(df)))\n",
    "df_temp = df.query('id != 62')\n",
    "df_temp['startdate'] = pd.to_datetime(np.arange(92), unit='D', origin=pd.Timestamp('2017-10-01'))\n",
    "df_temp.reset_index(inplace=True)\n",
    "df_temp.set_index('startdate')\n",
    "\n",
    "df_summ['startdate'] = pd.to_datetime(np.arange(92), unit='D', origin=pd.Timestamp('2017-10-01'))\n",
    "df_temp['LMT'] = df_temp['LMT'].astype(int)\n",
    "df_temp['AVGT'] = df_temp['AVGT'].astype(float)\n",
    "\n",
    "print(df_summ.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh.plotting as bkp\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "sns.set()\n",
    "\n",
    "file_list = ['../data/201710-citibike-tripdata.csv', '../data/201711-citibike-tripdata.csv', '../data/201712-citibike-tripdata.csv']\n",
    "\n",
    "df_sub = pd.DataFrame()\n",
    "df_cust = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "        data_sub = filter_csv_to_df(file, 'Y', 100000000)\n",
    "        \n",
    "        df_sub = pd.concat([df_sub, data_sub], axis=0)\n",
    "        \n",
    "        data_cust = filter_csv_to_df(file, 'N', 100000000)\n",
    "\n",
    "        df_cust = pd.concat([df_cust, data_cust], axis=0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3789518, 15)\n",
      "(328690, 15)\n"
     ]
    }
   ],
   "source": [
    "print (df_sub.shape)\n",
    "print (df_cust.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seperate DATES and TIME in standard format\n",
    "# Convert birth year to int, calculate User age and drop User with age > 99 (outliers)\n",
    "\n",
    "# Calculate Driver Age.\n",
    "df_sub = df_sub.dropna(subset = ['birth year'])\n",
    "df_cust = df_cust.dropna(subset = ['birth year'])\n",
    "\n",
    "df_sub['birth year'] = df_sub['birth year'].astype(int)\n",
    "df_cust['birth year'] = df_cust['birth year'].astype(int)\n",
    "\n",
    "df_sub['driver_age'] = pd.to_datetime('today').year-df_sub['birth year']\n",
    "df_cust['driver_age'] = pd.to_datetime('today').year-df_cust['birth year']\n",
    "\n",
    "\n",
    "df_sub = df_sub.query(\"driver_age < 100 \")\n",
    "df_cust = df_cust.query(\"driver_age < 100 \")\n",
    "\n",
    "### Rename Few column for easy reference\n",
    "\n",
    "df_sub = df_sub.rename(index=str, columns={\"start station id\": 'start_id', \"start station name\": \"start_name\"})\n",
    "df_cust = df_cust.rename(index=str, columns={\"start station id\": \"start_id\", \"start station name\": \"start_name\"})\n",
    "\n",
    "df_sub = df_sub.rename(index=str, columns={\"end station id\": \"end_id\", \"end station name\": \"end_name\"})\n",
    "df_cust = df_cust.rename(index=str, columns={\"end station id\": \"end_id\", \"end station name\": \"end_name\"})\n",
    "\n",
    "df_sub = df_sub.rename(index=str, columns={\"start station latitude\": \"start_lat\", \"start station longitude\": \"start_lon\"})\n",
    "df_cust = df_cust.rename(index=str, columns={\"start station latitude\": \"start_lat\", \"start station longitude\": \"start_lon\"})\n",
    "\n",
    "df_sub = df_sub.rename(index=str, columns={\"end station latitude\": \"end_lat\", \"end station longitude\": \"end_lon\"})\n",
    "df_cust = df_cust.rename(index=str, columns={\"end station latitude\": \"end_lat\", \"end station longitude\": \"end_lon\"})\n",
    "\n",
    "df_sub.insert(0, 'trip_id', range(1, 1 + len(df_sub)))\n",
    "df_cust.insert(0, 'trip_id', range(1, 1 + len(df_cust)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract date and hour from Datetime column\n",
    "# Create a unique trip id for each trip\n",
    "\n",
    "df_sub['startdate'] = pd.to_datetime(df_sub['starttime']).dt.date\n",
    "df_cust['startdate'] = pd.to_datetime(df_cust['starttime']).dt.date\n",
    "\n",
    "df_sub['starthour'] = pd.to_datetime(df_sub['starttime']).dt.hour\n",
    "df_cust['starthour'] = pd.to_datetime(df_cust['starttime']).dt.hour\n",
    "\n",
    "df_sub['enddate'] = pd.to_datetime(df_sub['stoptime']).dt.date\n",
    "df_cust['enddate'] = pd.to_datetime(df_cust['stoptime']).dt.date\n",
    "\n",
    "df_sub['endhour'] = pd.to_datetime(df_sub['stoptime']).dt.hour\n",
    "df_cust['endhour'] = pd.to_datetime(df_cust['stoptime']).dt.hour\n",
    "\n",
    "df_sub['start_day'] = pd.to_datetime(df_sub['starttime']).dt.dayofweek\n",
    "df_cust['start_day'] = pd.to_datetime(df_cust['starttime']).dt.dayofweek\n",
    "\n",
    "df_sub['end_day'] = pd.to_datetime(df_sub['stoptime']).dt.dayofweek\n",
    "df_cust['end_day'] = pd.to_datetime(df_cust['stoptime']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3726266, 26)\n",
      "(64431, 26)\n"
     ]
    }
   ],
   "source": [
    "# Create New columns to identify if Trip was free i.e covered in the pass or not\n",
    "# what are paid units of each trip and $ paid based on plans\n",
    "\n",
    "df_sub['free_trip'] = np.where(df_sub['tripduration'] <= 2700, 1, 0)\n",
    "df_cust['free_trip'] = np.where(df_cust['tripduration'] <= 1800, 1, 0)\n",
    "\n",
    "df_sub['paidunits'] = np.where(df_sub['free_trip'] == 0 ,np.ceil((df_sub['tripduration']-2700)/900), 0)\n",
    "df_cust['paidunits'] = np.where(df_cust['free_trip'] == 0 ,np.ceil((df_cust['tripduration']-1800)/900), 0)\n",
    "\n",
    "df_sub['paidamount'] = np.where(df_sub['paidunits'] > 0 ,df_sub['paidunits']*2.5, 0)\n",
    "df_cust['paidamount'] = np.where(df_cust['paidunits'] > 0 ,df_cust['paidunits']*4.0, 0)\n",
    "\n",
    "print (df_sub.shape)\n",
    "print (df_cust.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jitendra_agarwal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/jitendra_agarwal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_id</th>\n",
       "      <th>end_name</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>40.760301</td>\n",
       "      <td>-73.998842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350</td>\n",
       "      <td>Clinton St &amp; Grand St</td>\n",
       "      <td>40.715595</td>\n",
       "      <td>-73.987030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>468</td>\n",
       "      <td>Broadway &amp; W 56 St</td>\n",
       "      <td>40.765265</td>\n",
       "      <td>-73.981923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>305</td>\n",
       "      <td>E 58 St &amp; 3 Ave</td>\n",
       "      <td>40.760958</td>\n",
       "      <td>-73.967245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>355</td>\n",
       "      <td>Bayard St &amp; Baxter St</td>\n",
       "      <td>40.716021</td>\n",
       "      <td>-73.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>295</td>\n",
       "      <td>Pike St &amp; E Broadway</td>\n",
       "      <td>40.714067</td>\n",
       "      <td>-73.992939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3090</td>\n",
       "      <td>N 8 St &amp; Driggs Ave</td>\n",
       "      <td>40.717746</td>\n",
       "      <td>-73.956001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>458</td>\n",
       "      <td>11 Ave &amp; W 27 St</td>\n",
       "      <td>40.751396</td>\n",
       "      <td>-74.005226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3346</td>\n",
       "      <td>Berkeley Pl &amp; 7 Ave</td>\n",
       "      <td>40.675147</td>\n",
       "      <td>-73.975232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3314</td>\n",
       "      <td>W 95 St &amp; Broadway</td>\n",
       "      <td>40.793770</td>\n",
       "      <td>-73.971888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3109</td>\n",
       "      <td>Banker St &amp; Meserole Ave</td>\n",
       "      <td>40.726060</td>\n",
       "      <td>-73.956210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>537</td>\n",
       "      <td>Lexington Ave &amp; E 24 St</td>\n",
       "      <td>40.740259</td>\n",
       "      <td>-73.984092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>445</td>\n",
       "      <td>E 10 St &amp; Avenue A</td>\n",
       "      <td>40.727408</td>\n",
       "      <td>-73.981420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3076</td>\n",
       "      <td>Scholes St &amp; Manhattan Ave</td>\n",
       "      <td>40.708704</td>\n",
       "      <td>-73.944862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3429</td>\n",
       "      <td>Hanson Pl &amp; Ashland Pl</td>\n",
       "      <td>40.685068</td>\n",
       "      <td>-73.977908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>453</td>\n",
       "      <td>W 22 St &amp; 8 Ave</td>\n",
       "      <td>40.744751</td>\n",
       "      <td>-73.999154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>450</td>\n",
       "      <td>W 49 St &amp; 8 Ave</td>\n",
       "      <td>40.762272</td>\n",
       "      <td>-73.987882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>518</td>\n",
       "      <td>E 39 St &amp; 2 Ave</td>\n",
       "      <td>40.747804</td>\n",
       "      <td>-73.973442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3058</td>\n",
       "      <td>Lewis Ave &amp; Kosciuszko St</td>\n",
       "      <td>40.692371</td>\n",
       "      <td>-73.937054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3151</td>\n",
       "      <td>E 81 St &amp; York Ave</td>\n",
       "      <td>40.772838</td>\n",
       "      <td>-73.949892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>297</td>\n",
       "      <td>E 15 St &amp; 3 Ave</td>\n",
       "      <td>40.734232</td>\n",
       "      <td>-73.986923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3072</td>\n",
       "      <td>Leonard St &amp; Boerum St</td>\n",
       "      <td>40.705833</td>\n",
       "      <td>-73.946446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>501</td>\n",
       "      <td>FDR Drive &amp; E 35 St</td>\n",
       "      <td>40.744219</td>\n",
       "      <td>-73.971212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>509</td>\n",
       "      <td>9 Ave &amp; W 22 St</td>\n",
       "      <td>40.745497</td>\n",
       "      <td>-74.001971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>438</td>\n",
       "      <td>St Marks Pl &amp; 1 Ave</td>\n",
       "      <td>40.727791</td>\n",
       "      <td>-73.985649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>495</td>\n",
       "      <td>W 47 St &amp; 10 Ave</td>\n",
       "      <td>40.762699</td>\n",
       "      <td>-73.993012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3364</td>\n",
       "      <td>Carroll St &amp; 5 Ave</td>\n",
       "      <td>40.675162</td>\n",
       "      <td>-73.981483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>366</td>\n",
       "      <td>Clinton Ave &amp; Myrtle Ave</td>\n",
       "      <td>40.693261</td>\n",
       "      <td>-73.968896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>545</td>\n",
       "      <td>E 23 St &amp; 1 Ave</td>\n",
       "      <td>40.736502</td>\n",
       "      <td>-73.978095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>334</td>\n",
       "      <td>W 20 St &amp; 7 Ave</td>\n",
       "      <td>40.742388</td>\n",
       "      <td>-73.997262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552916</th>\n",
       "      <td>3587</td>\n",
       "      <td>Carroll St &amp; Washington Ave</td>\n",
       "      <td>40.668674</td>\n",
       "      <td>-73.961815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599249</th>\n",
       "      <td>3175</td>\n",
       "      <td>W 70 St &amp; Amsterdam Ave</td>\n",
       "      <td>40.777480</td>\n",
       "      <td>-73.982886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637770</th>\n",
       "      <td>3464</td>\n",
       "      <td>W 37 St &amp; Broadway</td>\n",
       "      <td>40.752271</td>\n",
       "      <td>-73.987706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666017</th>\n",
       "      <td>3623</td>\n",
       "      <td>W 120 St &amp; Claremont Ave</td>\n",
       "      <td>40.810949</td>\n",
       "      <td>-73.963400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854083</th>\n",
       "      <td>3647</td>\n",
       "      <td>48 Ave &amp; 30 Pl</td>\n",
       "      <td>40.741283</td>\n",
       "      <td>-73.937259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869389</th>\n",
       "      <td>3611</td>\n",
       "      <td>Vernon Blvd &amp; 47 Rd</td>\n",
       "      <td>40.744907</td>\n",
       "      <td>-73.953457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889586</th>\n",
       "      <td>3646</td>\n",
       "      <td>35 Ave &amp; 10 St</td>\n",
       "      <td>40.763155</td>\n",
       "      <td>-73.939855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69695</th>\n",
       "      <td>3575</td>\n",
       "      <td>Crescent St &amp; 34 Ave</td>\n",
       "      <td>40.761080</td>\n",
       "      <td>-73.930562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88587</th>\n",
       "      <td>3571</td>\n",
       "      <td>Bedford Ave &amp; Bergen St</td>\n",
       "      <td>40.676368</td>\n",
       "      <td>-73.952918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113178</th>\n",
       "      <td>3278</td>\n",
       "      <td>Monmouth and 6th</td>\n",
       "      <td>40.725685</td>\n",
       "      <td>-74.048790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209292</th>\n",
       "      <td>3277</td>\n",
       "      <td>Communipaw &amp; Berry Lane</td>\n",
       "      <td>40.714358</td>\n",
       "      <td>-74.066611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308831</th>\n",
       "      <td>3648</td>\n",
       "      <td>Flushing Ave &amp; Vanderbilt Ave</td>\n",
       "      <td>40.697950</td>\n",
       "      <td>-73.970776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310598</th>\n",
       "      <td>3550</td>\n",
       "      <td>Convent Ave &amp; W 129 St</td>\n",
       "      <td>40.814130</td>\n",
       "      <td>-73.953005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313029</th>\n",
       "      <td>3239</td>\n",
       "      <td>Bressler</td>\n",
       "      <td>40.646538</td>\n",
       "      <td>-74.016588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343534</th>\n",
       "      <td>3505</td>\n",
       "      <td>Lexington Ave &amp; E 127 St</td>\n",
       "      <td>40.805726</td>\n",
       "      <td>-73.936322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359651</th>\n",
       "      <td>515</td>\n",
       "      <td>W 43 St &amp; 10 Ave</td>\n",
       "      <td>40.760094</td>\n",
       "      <td>-73.994618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664822</th>\n",
       "      <td>3649</td>\n",
       "      <td>W 129 St &amp; Convent Ave</td>\n",
       "      <td>40.814394</td>\n",
       "      <td>-73.953247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758238</th>\n",
       "      <td>3650</td>\n",
       "      <td>8D Mobile 01</td>\n",
       "      <td>45.505851</td>\n",
       "      <td>-73.569109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047533</th>\n",
       "      <td>3240</td>\n",
       "      <td>NYCBS Depot BAL - DYR</td>\n",
       "      <td>40.759030</td>\n",
       "      <td>-73.993859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112877</th>\n",
       "      <td>3192</td>\n",
       "      <td>Liberty Light Rail</td>\n",
       "      <td>40.711242</td>\n",
       "      <td>-74.055701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147810</th>\n",
       "      <td>3155</td>\n",
       "      <td>Lexington Ave &amp; E 63 St</td>\n",
       "      <td>40.764400</td>\n",
       "      <td>-73.966490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33020</th>\n",
       "      <td>3036</td>\n",
       "      <td>8D OPS 01</td>\n",
       "      <td>40.880921</td>\n",
       "      <td>-73.896602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33117</th>\n",
       "      <td>3488</td>\n",
       "      <td>8D QC Station 01</td>\n",
       "      <td>45.506364</td>\n",
       "      <td>-73.569463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659957</th>\n",
       "      <td>3198</td>\n",
       "      <td>Heights Elevator</td>\n",
       "      <td>40.748716</td>\n",
       "      <td>-74.040443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673910</th>\n",
       "      <td>3148</td>\n",
       "      <td>E 84 St &amp; 1 Ave</td>\n",
       "      <td>40.775655</td>\n",
       "      <td>-73.950686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692643</th>\n",
       "      <td>3645</td>\n",
       "      <td>Pathmark Depot</td>\n",
       "      <td>40.672333</td>\n",
       "      <td>-73.997061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735530</th>\n",
       "      <td>3654</td>\n",
       "      <td>31 St &amp; Northern Blvd</td>\n",
       "      <td>40.751870</td>\n",
       "      <td>-73.933493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771868</th>\n",
       "      <td>3653</td>\n",
       "      <td>31 St &amp; 35 Ave</td>\n",
       "      <td>40.758205</td>\n",
       "      <td>-73.928322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882667</th>\n",
       "      <td>3543</td>\n",
       "      <td>Morningside Dr &amp; Amsterdam Ave</td>\n",
       "      <td>40.810285</td>\n",
       "      <td>-73.957365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883580</th>\n",
       "      <td>3631</td>\n",
       "      <td>Crown St &amp; Bedford Ave</td>\n",
       "      <td>40.666563</td>\n",
       "      <td>-73.956741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>803 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         end_id                        end_name    end_lat    end_lon\n",
       "0           478                11 Ave & W 41 St  40.760301 -73.998842\n",
       "2           350           Clinton St & Grand St  40.715595 -73.987030\n",
       "5           468              Broadway & W 56 St  40.765265 -73.981923\n",
       "7           305                 E 58 St & 3 Ave  40.760958 -73.967245\n",
       "8           355           Bayard St & Baxter St  40.716021 -73.999744\n",
       "9           295            Pike St & E Broadway  40.714067 -73.992939\n",
       "10         3090             N 8 St & Driggs Ave  40.717746 -73.956001\n",
       "12          458                11 Ave & W 27 St  40.751396 -74.005226\n",
       "13         3346             Berkeley Pl & 7 Ave  40.675147 -73.975232\n",
       "14         3314              W 95 St & Broadway  40.793770 -73.971888\n",
       "16         3109        Banker St & Meserole Ave  40.726060 -73.956210\n",
       "17          537         Lexington Ave & E 24 St  40.740259 -73.984092\n",
       "19          445              E 10 St & Avenue A  40.727408 -73.981420\n",
       "20         3076      Scholes St & Manhattan Ave  40.708704 -73.944862\n",
       "21         3429          Hanson Pl & Ashland Pl  40.685068 -73.977908\n",
       "22          453                 W 22 St & 8 Ave  40.744751 -73.999154\n",
       "23          450                 W 49 St & 8 Ave  40.762272 -73.987882\n",
       "24          518                 E 39 St & 2 Ave  40.747804 -73.973442\n",
       "25         3058       Lewis Ave & Kosciuszko St  40.692371 -73.937054\n",
       "27         3151              E 81 St & York Ave  40.772838 -73.949892\n",
       "28          297                 E 15 St & 3 Ave  40.734232 -73.986923\n",
       "29         3072          Leonard St & Boerum St  40.705833 -73.946446\n",
       "32          501             FDR Drive & E 35 St  40.744219 -73.971212\n",
       "33          509                 9 Ave & W 22 St  40.745497 -74.001971\n",
       "34          438             St Marks Pl & 1 Ave  40.727791 -73.985649\n",
       "35          495                W 47 St & 10 Ave  40.762699 -73.993012\n",
       "36         3364              Carroll St & 5 Ave  40.675162 -73.981483\n",
       "37          366        Clinton Ave & Myrtle Ave  40.693261 -73.968896\n",
       "38          545                 E 23 St & 1 Ave  40.736502 -73.978095\n",
       "41          334                 W 20 St & 7 Ave  40.742388 -73.997262\n",
       "...         ...                             ...        ...        ...\n",
       "1552916    3587     Carroll St & Washington Ave  40.668674 -73.961815\n",
       "1599249    3175         W 70 St & Amsterdam Ave  40.777480 -73.982886\n",
       "1637770    3464              W 37 St & Broadway  40.752271 -73.987706\n",
       "1666017    3623        W 120 St & Claremont Ave  40.810949 -73.963400\n",
       "1854083    3647                  48 Ave & 30 Pl  40.741283 -73.937259\n",
       "1869389    3611             Vernon Blvd & 47 Rd  40.744907 -73.953457\n",
       "1889586    3646                  35 Ave & 10 St  40.763155 -73.939855\n",
       "69695      3575            Crescent St & 34 Ave  40.761080 -73.930562\n",
       "88587      3571         Bedford Ave & Bergen St  40.676368 -73.952918\n",
       "113178     3278                Monmouth and 6th  40.725685 -74.048790\n",
       "209292     3277         Communipaw & Berry Lane  40.714358 -74.066611\n",
       "308831     3648   Flushing Ave & Vanderbilt Ave  40.697950 -73.970776\n",
       "310598     3550          Convent Ave & W 129 St  40.814130 -73.953005\n",
       "313029     3239                        Bressler  40.646538 -74.016588\n",
       "343534     3505        Lexington Ave & E 127 St  40.805726 -73.936322\n",
       "359651      515                W 43 St & 10 Ave  40.760094 -73.994618\n",
       "664822     3649          W 129 St & Convent Ave  40.814394 -73.953247\n",
       "758238     3650                    8D Mobile 01  45.505851 -73.569109\n",
       "1047533    3240           NYCBS Depot BAL - DYR  40.759030 -73.993859\n",
       "1112877    3192              Liberty Light Rail  40.711242 -74.055701\n",
       "1147810    3155         Lexington Ave & E 63 St  40.764400 -73.966490\n",
       "33020      3036                       8D OPS 01  40.880921 -73.896602\n",
       "33117      3488                8D QC Station 01  45.506364 -73.569463\n",
       "659957     3198                Heights Elevator  40.748716 -74.040443\n",
       "673910     3148                 E 84 St & 1 Ave  40.775655 -73.950686\n",
       "692643     3645                  Pathmark Depot  40.672333 -73.997061\n",
       "735530     3654           31 St & Northern Blvd  40.751870 -73.933493\n",
       "771868     3653                  31 St & 35 Ave  40.758205 -73.928322\n",
       "882667     3543  Morningside Dr & Amsterdam Ave  40.810285 -73.957365\n",
       "883580     3631          Crown St & Bedford Ave  40.666563 -73.956741\n",
       "\n",
       "[803 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DF for unique list of station\n",
    "\n",
    "df_station1 = df_sub[['start_id', 'start_name', 'start_lat', 'start_lon']]\n",
    "df_station2 = df_sub[['end_id', 'end_name', 'end_lat', 'end_lon']]\n",
    "\n",
    "df_station1['start_id'] = df_sub['start_id'].astype(int)\n",
    "df_station2['end_id'] = df_sub['end_id'].astype(int)\n",
    "\n",
    "df_station1.drop_duplicates()\n",
    "df_station2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 772 entries, 26364 to 819070\n",
      "Data columns (total 4 columns):\n",
      "station_id      772 non-null int64\n",
      "station_name    772 non-null object\n",
      "station_lat     772 non-null float64\n",
      "station_lon     772 non-null float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 30.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create a Df for unique list of station\n",
    "df_station1.append(df_station2)\n",
    "\n",
    "df_stations = df_station1.rename(index=str, columns={\"start_id\": 'station_id', \"start_name\": \"station_name\", \"start_lat\": 'station_lat', \"start_lon\": \"station_lon\"})\n",
    "\n",
    "df_stations.set_index(['station_id'], append=True)\n",
    "df_stations = df_stations.sort_values(['station_id']).drop_duplicates(subset=['station_id'])\n",
    "\n",
    "print(df_stations.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>near_count</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>473</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>516</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>530</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>483</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   near_count  origin\n",
       "0         473      72\n",
       "1         516      79\n",
       "2         530      82\n",
       "3         413      83\n",
       "4         483     116"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "near_df = []\n",
    "k = len(df_stations)\n",
    "for i in range(0, k):\n",
    "    near_count = 0\n",
    "    for j in range(0, k):\n",
    "        near =  mile_distance(df_stations.iloc[i]['station_lon'], df_stations.iloc[i]['station_lat'], df_stations.iloc[j]['station_lon'], df_stations.iloc[j]['station_lat'])\n",
    "        near_count  = near_count + near;\n",
    "        near_df.append(near_count)\n",
    "    df.append({'near_count': near_count, 'origin': df_stations.iloc[i]['station_id']})    \n",
    "    df_near = pd.DataFrame(df)\n",
    "\n",
    "df_near.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "As per Citi Bike, avg distance traveled per second in miles is= 0.0020711111111111112\n",
      "Total unique bikes used by subscribers in Q4= 13054\n",
      "Total No of Trips by subscribers in Q4= 3726266\n",
      "Each Subscriber pays per month= 14.95\n",
      "--------------------------------------------------------------------------\n",
      "           total_trip_time  no_of_bikes  no_of_trips  paidunits month  \\\n",
      "startdate                                                               \n",
      "10              1355418246        11516      1663401   150177.0   OCT   \n",
      "11               916593277        12773      1220354    85229.0   NOV   \n",
      "12               602049732        11109       842511    57415.0   DEC   \n",
      "\n",
      "           total_distance  avg_dis_per_trip  avg_time_per_trip  \\\n",
      "startdate                                                        \n",
      "10             2807221.79              1.69              13.58   \n",
      "11             1898366.52              1.56              12.52   \n",
      "12             1246911.89              1.48              11.91   \n",
      "\n",
      "           avg_trip_per_bike  avg_dis_per_bike  avg_time_per_bike  \\\n",
      "startdate                                                           \n",
      "10                    144.44            243.77            1961.65   \n",
      "11                     95.54            148.62            1196.00   \n",
      "12                     75.84            112.24             903.25   \n",
      "\n",
      "           paid_trip_revenue_bysubs  paid_trip_monthly_revenue  \\\n",
      "startdate                                                        \n",
      "10                         375442.5                  1601814.5   \n",
      "11                         213072.5                   596424.5   \n",
      "12                         143537.5                   187465.5   \n",
      "\n",
      "           paid_trip_revenue_bycust  avg_reven_per_bike  avg_reven_per_trip  \n",
      "startdate                                                                    \n",
      "10                        1226372.0              436.28                3.02  \n",
      "11                         383352.0              393.35                4.12  \n",
      "12                          43928.0              452.27                5.96  \n",
      "--------------------------------------------------------------------------\n",
      "        Trips    Miles  Members  24-Hour-Passes  3-Day-Passes  \\\n",
      "Date                                                            \n",
      "10    1897533  4061321   250892           61150          7172   \n",
      "11    1330612  2674409   252414           27767          2985   \n",
      "12     889958  1814149   253443           11838          1168   \n",
      "\n",
      "      pass_revenue_bysubs  pass_revenue_bycust_1d  pass_revenue_bycust_3d  \\\n",
      "Date                                                                        \n",
      "10             3750835.40                  733800                  172128   \n",
      "11             3773589.30                  333204                   71640   \n",
      "12             3788972.85                  142056                   28032   \n",
      "\n",
      "      All_pass_monthly_revenue  \n",
      "Date                            \n",
      "10                  4656763.40  \n",
      "11                  4178433.30  \n",
      "12                  3959060.85  \n",
      "--------------------------------------------------------------------------\n",
      "Total Q4 Revenue =  15179962.0\n",
      "Average monthly Revenue =  5059987.0\n"
     ]
    }
   ],
   "source": [
    "#Calculate Unit Economics and create Monthly summary and calculate total monthyl revenue based on pricing\n",
    "\n",
    "trip_bymonth = df_sub.groupby(pd.to_datetime(df_sub['startdate']).dt.month).agg({'tripduration': 'sum', 'bikeid':'nunique', 'trip_id':'count', 'paidunits':'sum' })\n",
    "trip_bymonth = trip_bymonth.rename(index=str, columns={\"tripduration\": 'total_trip_time', \"bikeid\": \"no_of_bikes\", \"trip_id\": \"no_of_trips\"})\n",
    "\n",
    "trip_bymonth_cust = df_cust.groupby(pd.to_datetime(df_cust['startdate']).dt.month).agg({'tripduration': 'sum', 'bikeid':'nunique', 'start_id':'count', 'paidunits':'sum' })\n",
    "trip_bymonth_cust = trip_bymonth_cust.rename(index=str, columns={\"tripduration\": 'total_trip_time', \"bikeid\": \"no_of_bikes\", \"start_id\": \"no_of_trips\"})\n",
    "\n",
    "trip_bymonth_summ = df_summ.groupby(pd.to_datetime(df_summ['Date']).dt.month).agg({'Trips': 'sum', 'Miles':'sum', 'Members':'max', '24-Hour-Passes':'sum', '3-Day-Passes':'sum' })\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "\n",
    "avg_mile=7.456/60/60\n",
    "print('As per Citi Bike, avg distance traveled per second in miles is=',avg_mile ) \n",
    "print('Total unique bikes used by subscribers in Q4=',len(df_sub['bikeid'].unique() )) \n",
    "print('Total No of Trips by subscribers in Q4=',len(df_sub['bikeid']) )\n",
    "print('Each Subscriber pays per month=', 14.95)\n",
    "print('--------------------------------------------------------------------------')\n",
    "\n",
    "#caclulate total mile traveled, average mile per bike, avg time per bike, average mile per trip, average time per trip\n",
    "trip_bymonth['month'] = ['OCT', 'NOV', 'DEC']\n",
    "trip_bymonth['total_distance'] = np.around(trip_bymonth['total_trip_time']*avg_mile, decimals=2)\n",
    "\n",
    "trip_bymonth['avg_dis_per_trip'] = np.around(trip_bymonth['total_distance']/trip_bymonth['no_of_trips'], decimals=2)\n",
    "trip_bymonth['avg_time_per_trip'] = np.around((trip_bymonth['total_trip_time']/trip_bymonth['no_of_trips'])/60, decimals=2)\n",
    "\n",
    "trip_bymonth['avg_trip_per_bike'] = np.around(trip_bymonth['no_of_trips']/trip_bymonth['no_of_bikes'], decimals=2)\n",
    "trip_bymonth['avg_dis_per_bike'] = np.around(trip_bymonth['total_distance']/trip_bymonth['no_of_bikes'], decimals=2)\n",
    "trip_bymonth['avg_time_per_bike'] = np.around((trip_bymonth['total_trip_time']/trip_bymonth['no_of_bikes'])/60, decimals=2)\n",
    "\n",
    "trip_bymonth_summ['pass_revenue_bysubs'] = np.around(trip_bymonth_summ['Members']*14.95, decimals=2)\n",
    "trip_bymonth_summ['pass_revenue_bycust_1d'] = np.around(trip_bymonth_summ['24-Hour-Passes']*12, decimals=2)\n",
    "trip_bymonth_summ['pass_revenue_bycust_3d'] = np.around(trip_bymonth_summ['3-Day-Passes']*24, decimals=2)\n",
    "\n",
    "trip_bymonth['paid_trip_revenue_bysubs'] = np.around(trip_bymonth['paidunits']*2.5, decimals=2)\n",
    "trip_bymonth_cust['paid_trip_revenue_bycust'] = np.around(trip_bymonth_cust['paidunits']*4, decimals=2)\n",
    "\n",
    "trip_bymonth['paid_trip_monthly_revenue'] = trip_bymonth['paid_trip_revenue_bysubs']+trip_bymonth_cust['paid_trip_revenue_bycust']\n",
    "trip_bymonth['paid_trip_revenue_bycust'] = trip_bymonth['paid_trip_monthly_revenue']-trip_bymonth['paid_trip_revenue_bysubs']\n",
    "\n",
    "trip_bymonth_summ['All_pass_monthly_revenue'] = trip_bymonth_summ['pass_revenue_bysubs'] + trip_bymonth_summ['pass_revenue_bycust_1d'] + trip_bymonth_summ['pass_revenue_bycust_3d']\n",
    "\n",
    "trip_bymonth['avg_reven_per_bike'] = np.around(5024220/trip_bymonth['no_of_bikes'], decimals=2)\n",
    "trip_bymonth['avg_reven_per_trip'] = np.around(5024220/trip_bymonth['no_of_trips'], decimals=2)\n",
    "\n",
    "print(trip_bymonth)\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(trip_bymonth_summ)\n",
    "print('--------------------------------------------------------------------------')\n",
    "\n",
    "print(\"Total Q4 Revenue = \" ,np.around(trip_bymonth_summ['All_pass_monthly_revenue'].sum() + trip_bymonth['paid_trip_monthly_revenue'].sum()))\n",
    "print(\"Average monthly Revenue = \" , np.around((trip_bymonth_summ['All_pass_monthly_revenue'].sum() + trip_bymonth['paid_trip_monthly_revenue'].sum())/3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_id  tripduration  start_id  start_lat  start_lon  end_id    end_lat  \\\n",
      "0        1           457       479  40.760193 -73.991255     478  40.760301   \n",
      "2        2           761       504  40.732219 -73.981656     350  40.715595   \n",
      "5        3           260      3443  40.761330 -73.979820     468  40.765265   \n",
      "7        4           808      3305  40.781122 -73.949656     305  40.760958   \n",
      "8        5          1143       284  40.739017 -74.002638     355  40.716021   \n",
      "\n",
      "     end_lon  bikeid    usertype     ...      driver_age   startdate  \\\n",
      "0 -73.998842   30951  Subscriber     ...              33  2017-10-01   \n",
      "2 -73.987030   28713  Subscriber     ...              26  2017-10-01   \n",
      "5 -73.981923   27600  Subscriber     ...              28  2017-10-01   \n",
      "7 -73.967245   17737  Subscriber     ...              25  2017-10-01   \n",
      "8 -73.999744   20172  Subscriber     ...              26  2017-10-01   \n",
      "\n",
      "  starthour     enddate endhour  start_day  end_day  free_trip  paidunits  \\\n",
      "0         0  2017-10-01       0          6        6          1        0.0   \n",
      "2         0  2017-10-01       0          6        6          1        0.0   \n",
      "5         0  2017-10-01       0          6        6          1        0.0   \n",
      "7         0  2017-10-01       0          6        6          1        0.0   \n",
      "8         0  2017-10-01       0          6        6          1        0.0   \n",
      "\n",
      "   paidamount  \n",
      "0         0.0  \n",
      "2         0.0  \n",
      "5         0.0  \n",
      "7         0.0  \n",
      "8         0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>end_id</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>gender</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>starthour</th>\n",
       "      <th>endhour</th>\n",
       "      <th>start_day</th>\n",
       "      <th>end_day</th>\n",
       "      <th>free_trip</th>\n",
       "      <th>paidunits</th>\n",
       "      <th>paidamount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>3.726266e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.863134e+06</td>\n",
       "      <td>7.712979e+02</td>\n",
       "      <td>1.440701e+03</td>\n",
       "      <td>4.073716e+01</td>\n",
       "      <td>-7.398286e+01</td>\n",
       "      <td>1.428904e+03</td>\n",
       "      <td>4.073715e+01</td>\n",
       "      <td>-7.398373e+01</td>\n",
       "      <td>2.559676e+04</td>\n",
       "      <td>1.241310e+00</td>\n",
       "      <td>3.903543e+01</td>\n",
       "      <td>1.367407e+01</td>\n",
       "      <td>1.381377e+01</td>\n",
       "      <td>2.706733e+00</td>\n",
       "      <td>2.707514e+00</td>\n",
       "      <td>9.930877e-01</td>\n",
       "      <td>7.858296e-02</td>\n",
       "      <td>1.964574e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.075680e+06</td>\n",
       "      <td>1.039112e+04</td>\n",
       "      <td>1.388033e+03</td>\n",
       "      <td>1.244255e-01</td>\n",
       "      <td>2.175515e-01</td>\n",
       "      <td>1.385444e+03</td>\n",
       "      <td>4.591808e-02</td>\n",
       "      <td>5.712936e-02</td>\n",
       "      <td>5.982522e+03</td>\n",
       "      <td>4.392722e-01</td>\n",
       "      <td>1.186143e+01</td>\n",
       "      <td>4.900341e+00</td>\n",
       "      <td>4.928896e+00</td>\n",
       "      <td>1.891782e+00</td>\n",
       "      <td>1.892211e+00</td>\n",
       "      <td>8.285230e-02</td>\n",
       "      <td>1.152036e+01</td>\n",
       "      <td>2.880089e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.100000e+01</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.403423e+01</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.406692e+01</td>\n",
       "      <td>1.452900e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.315672e+05</td>\n",
       "      <td>3.410000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>4.071912e+01</td>\n",
       "      <td>-7.399490e+01</td>\n",
       "      <td>3.680000e+02</td>\n",
       "      <td>4.071911e+01</td>\n",
       "      <td>-7.399530e+01</td>\n",
       "      <td>1.956700e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.863134e+06</td>\n",
       "      <td>5.500000e+02</td>\n",
       "      <td>4.950000e+02</td>\n",
       "      <td>4.073902e+01</td>\n",
       "      <td>-7.398683e+01</td>\n",
       "      <td>4.920000e+02</td>\n",
       "      <td>4.073827e+01</td>\n",
       "      <td>-7.398700e+01</td>\n",
       "      <td>2.739700e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.794700e+06</td>\n",
       "      <td>9.080000e+02</td>\n",
       "      <td>3.166000e+03</td>\n",
       "      <td>4.075641e+01</td>\n",
       "      <td>-7.397536e+01</td>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>4.075527e+01</td>\n",
       "      <td>-7.397575e+01</td>\n",
       "      <td>3.093300e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.800000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.726266e+06</td>\n",
       "      <td>6.974419e+06</td>\n",
       "      <td>3.654000e+03</td>\n",
       "      <td>4.550585e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.654000e+03</td>\n",
       "      <td>4.550636e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.348100e+04</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.747000e+03</td>\n",
       "      <td>1.936750e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trip_id  tripduration      start_id     start_lat     start_lon  \\\n",
       "count  3.726266e+06  3.726266e+06  3.726266e+06  3.726266e+06  3.726266e+06   \n",
       "mean   1.863134e+06  7.712979e+02  1.440701e+03  4.073716e+01 -7.398286e+01   \n",
       "std    1.075680e+06  1.039112e+04  1.388033e+03  1.244255e-01  2.175515e-01   \n",
       "min    1.000000e+00  6.100000e+01  7.200000e+01  0.000000e+00 -7.403423e+01   \n",
       "25%    9.315672e+05  3.410000e+02  3.730000e+02  4.071912e+01 -7.399490e+01   \n",
       "50%    1.863134e+06  5.500000e+02  4.950000e+02  4.073902e+01 -7.398683e+01   \n",
       "75%    2.794700e+06  9.080000e+02  3.166000e+03  4.075641e+01 -7.397536e+01   \n",
       "max    3.726266e+06  6.974419e+06  3.654000e+03  4.550585e+01  0.000000e+00   \n",
       "\n",
       "             end_id       end_lat       end_lon        bikeid        gender  \\\n",
       "count  3.726266e+06  3.726266e+06  3.726266e+06  3.726266e+06  3.726266e+06   \n",
       "mean   1.428904e+03  4.073715e+01 -7.398373e+01  2.559676e+04  1.241310e+00   \n",
       "std    1.385444e+03  4.591808e-02  5.712936e-02  5.982522e+03  4.392722e-01   \n",
       "min    7.200000e+01  0.000000e+00 -7.406692e+01  1.452900e+04  0.000000e+00   \n",
       "25%    3.680000e+02  4.071911e+01 -7.399530e+01  1.956700e+04  1.000000e+00   \n",
       "50%    4.920000e+02  4.073827e+01 -7.398700e+01  2.739700e+04  1.000000e+00   \n",
       "75%    3.164000e+03  4.075527e+01 -7.397575e+01  3.093300e+04  1.000000e+00   \n",
       "max    3.654000e+03  4.550636e+01  0.000000e+00  3.348100e+04  2.000000e+00   \n",
       "\n",
       "         driver_age     starthour       endhour     start_day       end_day  \\\n",
       "count  3.726266e+06  3.726266e+06  3.726266e+06  3.726266e+06  3.726266e+06   \n",
       "mean   3.903543e+01  1.367407e+01  1.381377e+01  2.706733e+00  2.707514e+00   \n",
       "std    1.186143e+01  4.900341e+00  4.928896e+00  1.891782e+00  1.892211e+00   \n",
       "min    1.700000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    3.000000e+01  9.000000e+00  9.000000e+00  1.000000e+00  1.000000e+00   \n",
       "50%    3.600000e+01  1.400000e+01  1.400000e+01  3.000000e+00  3.000000e+00   \n",
       "75%    4.800000e+01  1.800000e+01  1.800000e+01  4.000000e+00  4.000000e+00   \n",
       "max    9.800000e+01  2.300000e+01  2.300000e+01  6.000000e+00  6.000000e+00   \n",
       "\n",
       "          free_trip     paidunits    paidamount  \n",
       "count  3.726266e+06  3.726266e+06  3.726266e+06  \n",
       "mean   9.930877e-01  7.858296e-02  1.964574e-01  \n",
       "std    8.285230e-02  1.152036e+01  2.880089e+01  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    1.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    1.000000e+00  0.000000e+00  0.000000e+00  \n",
       "75%    1.000000e+00  0.000000e+00  0.000000e+00  \n",
       "max    1.000000e+00  7.747000e+03  1.936750e+04  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Few more cleanup and Descibe the dataframe.\n",
    "df_sub['starthour'] = df_sub['starthour'].astype(int)\n",
    "df_sub['endhour'] = df_sub['endhour'].astype(int)\n",
    "df_sub['start_day'] = df_sub['start_day'].astype(int)\n",
    "\n",
    "# Drop columns which are not needed to make df lighter \n",
    "\n",
    "df_sub.drop(['starttime', 'stoptime', 'start_name', 'end_name', 'birth year'], axis=1, inplace=True)\n",
    "df_cust.drop(['starttime', 'stoptime', 'start_name', 'end_name', 'birth year'], axis=1, inplace=True)\n",
    "\n",
    "print(df_sub.head())\n",
    "df_sub.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculated Average Monthly Revenue is  $5,024,220\n",
    "###### --------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 65729 entries, 0 to 65728\n",
      "Data columns (total 22 columns):\n",
      "start_id           65729 non-null int64\n",
      "startdate          65729 non-null datetime64[ns]\n",
      "total_trip_time    65729 non-null int64\n",
      "no_of_bikes        65729 non-null int64\n",
      "no_of_trips        65729 non-null int64\n",
      "paidunits          65729 non-null float64\n",
      "free_trip          65729 non-null int64\n",
      "median_user_age    65729 non-null float64\n",
      "paidamount         65729 non-null float64\n",
      "gen_othr           65729 non-null uint8\n",
      "gen_male           65729 non-null float64\n",
      "gen_female         65729 non-null uint8\n",
      "day_0              65729 non-null float64\n",
      "day_1              65729 non-null float64\n",
      "day_2              65729 non-null float64\n",
      "day_3              65729 non-null float64\n",
      "day_4              65729 non-null float64\n",
      "day_5              65729 non-null float64\n",
      "day_6              65729 non-null float64\n",
      "density_score      65729 non-null int64\n",
      "AVGT               65729 non-null float64\n",
      "Members            65729 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(12), int64(7), uint8(2)\n",
      "memory usage: 10.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create another monthly summary DF with the encoded columns\n",
    "\n",
    "df_new11 = df_sub.query(\"driver_age < 75 \")\n",
    "df_new1 = df_new11.query(\"tripduration < 28800 \")\n",
    "\n",
    "df_new1 = pd.get_dummies(df_new1, columns=['gender', 'start_day'], prefix=['gen', 'day'])\n",
    "\n",
    "\n",
    "df_daily_trips_en = df_new1.groupby(['start_id','startdate'], as_index=False).agg({'tripduration': 'sum', 'bikeid':'nunique', 'trip_id':'count', 'paidunits':'sum', 'free_trip':'sum', 'driver_age':'median', 'paidamount':'sum',\n",
    "                                                                              'gen_0':'sum','gen_1':'sum', 'gen_2':'sum', 'day_0':'sum', 'day_1':'sum', 'day_2':'sum', 'day_3':'sum', \n",
    "                                                                               'day_4':'sum', 'day_5':'sum', 'day_6':'sum' })\n",
    "df_daily_trips_en = df_daily_trips_en.rename(index=str, columns={\"tripduration\": 'total_trip_time', \"bikeid\": \"no_of_bikes\", \"trip_id\": \"no_of_trips\", 'driver_age' :'median_user_age', 'gen_0' :'gen_othr', 'gen_1' :'gen_male', 'gen_2' :'gen_female'})\n",
    "df_daily_trips_en['startdate'] = pd.to_datetime(df_daily_trips_en['startdate'])\n",
    "\n",
    "df_near = df_near.rename(index=str, columns={\"origin\": 'start_id'})\n",
    "\n",
    "df_daily_trips_en = df_daily_trips_en.merge(df_near, how='left', on='start_id')\n",
    "df_daily_trips_en = df_daily_trips_en.merge(df_temp[['startdate', 'AVGT']], how='left', on='startdate')\n",
    "df_daily_trips_en = df_daily_trips_en.merge(df_summ[['startdate', 'Members']], how='left', on='startdate')\n",
    "\n",
    "df_daily_trips_en = df_daily_trips_en.rename(index=str, columns={\"near_count\": 'density_score' })\n",
    "print(df_daily_trips_en.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_id</th>\n",
       "      <th>startdate</th>\n",
       "      <th>total_trip_time</th>\n",
       "      <th>no_of_bikes</th>\n",
       "      <th>no_of_trips</th>\n",
       "      <th>paidunits</th>\n",
       "      <th>free_trip</th>\n",
       "      <th>start_day</th>\n",
       "      <th>median_user_age</th>\n",
       "      <th>paidamount</th>\n",
       "      <th>gender</th>\n",
       "      <th>density_score</th>\n",
       "      <th>AVGT</th>\n",
       "      <th>Members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>105707</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473</td>\n",
       "      <td>61.0</td>\n",
       "      <td>246193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>120738</td>\n",
       "      <td>125</td>\n",
       "      <td>131</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473</td>\n",
       "      <td>65.0</td>\n",
       "      <td>246402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>128572</td>\n",
       "      <td>135</td>\n",
       "      <td>140</td>\n",
       "      <td>3.0</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473</td>\n",
       "      <td>65.0</td>\n",
       "      <td>246566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>146306</td>\n",
       "      <td>152</td>\n",
       "      <td>159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473</td>\n",
       "      <td>66.5</td>\n",
       "      <td>246742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>148665</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>8.0</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>36.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473</td>\n",
       "      <td>75.0</td>\n",
       "      <td>246893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_id  startdate  total_trip_time  no_of_bikes  no_of_trips  paidunits  \\\n",
       "0        72 2017-10-01           105707           98          100        1.0   \n",
       "1        72 2017-10-02           120738          125          131        2.0   \n",
       "2        72 2017-10-03           128572          135          140        3.0   \n",
       "3        72 2017-10-04           146306          152          159        0.0   \n",
       "4        72 2017-10-05           148665          160          162        8.0   \n",
       "\n",
       "   free_trip  start_day  median_user_age  paidamount  gender  density_score  \\\n",
       "0         99          6             35.0         2.5     1.0            473   \n",
       "1        130          0             38.0         5.0     1.0            473   \n",
       "2        139          1             36.0         7.5     1.0            473   \n",
       "3        159          2             36.0         0.0     1.0            473   \n",
       "4        160          3             36.5        20.0     1.0            473   \n",
       "\n",
       "   AVGT  Members  \n",
       "0  61.0   246193  \n",
       "1  65.0   246402  \n",
       "2  65.0   246566  \n",
       "3  66.5   246742  \n",
       "4  75.0   246893  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new summary dataframe for oct, daily summary per station\n",
    "#add customer and subs together then \n",
    "#station id, date:- day, no of trips, total trip duration, avg trip duration, density score, freetrip flag, paid trips units,\n",
    "#we will also drop the record with user age more than 75 considering it as outlier\n",
    "\n",
    "df_new = df_sub.query(\"driver_age <= 75 \")\n",
    "df_new1 = df_new.query(\"tripduration < 28800 \")\n",
    "\n",
    "df_daily_trips = df_new1.groupby(['start_id','startdate'], as_index=False).agg({'tripduration': 'sum', 'bikeid':'nunique', 'trip_id':'count', 'paidunits':'sum', 'free_trip':'sum', 'start_day': 'max', 'driver_age':'median', 'paidamount':'sum', 'gender':'median' })\n",
    "df_daily_trips = df_daily_trips.rename(index=str, columns={\"tripduration\": 'total_trip_time', \"bikeid\": \"no_of_bikes\", \"trip_id\": \"no_of_trips\", 'driver_age' :'median_user_age'})\n",
    "df_daily_trips['startdate'] = pd.to_datetime(df_daily_trips['startdate'])\n",
    "\n",
    "df_near = df_near.rename(index=str, columns={\"origin\": 'start_id'})\n",
    "\n",
    "df_daily_trips = df_daily_trips.merge(df_near, how='left', on='start_id')\n",
    "df_daily_trips = df_daily_trips.merge(df_temp[['startdate', 'AVGT']], how='left', on='startdate')\n",
    "df_daily_trips = df_daily_trips.merge(df_summ[['startdate', 'Members']], how='left', on='startdate')\n",
    "\n",
    "df_daily_trips = df_daily_trips.rename(index=str, columns={\"near_count\": 'density_score' })\n",
    "\n",
    "df_daily_trips.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        start_id  end_id  tripduration  counts  paidunits  paidratio\n",
      "63940        432    3263        525349    1999        3.0   0.001501\n",
      "73775        460    3093        392324    1222       55.0   0.045008\n",
      "64962        435     509        358050    1191        7.0   0.005877\n",
      "93554        519     498        483084    1161        0.0   0.000000\n",
      "93548        519     491        450729    1074        4.0   0.003724\n",
      "89531        505     519        472928    1046        0.0   0.000000\n",
      "177165      3430    3086        208018    1045        0.0   0.000000\n",
      "119524      3107    3090        265962    1041       11.0   0.010567\n",
      "121771      3118    3119        357119    1032        6.0   0.005814\n",
      "117235      3093     460        323889    1024        3.0   0.002930\n",
      "145380      3263     432        282424    1010        0.0   0.000000\n",
      "93549        519     492        494381    1002        5.0   0.004990\n",
      "160251      3351    3318        232651     996        1.0   0.001004\n",
      "11627        239     270        298680     990        2.0   0.002020\n",
      "142789      3244     382        164175     982        0.0   0.000000\n",
      "16090        258     324        234387     972        0.0   0.000000\n",
      "122016      3119    3118        365659     952       55.0   0.057773\n",
      "22939        285     335        283098     950       87.0   0.091579\n",
      "102964      2002    3093        151228     936        0.0   0.000000\n",
      "93536        519     477        424237     925        0.0   0.000000\n",
      "The Most busy route is between #432 and #3263\n",
      "The Most busy station is #519\n"
     ]
    }
   ],
   "source": [
    "# Top Trip Routes\n",
    "\n",
    "newdf = df_sub.groupby(['start_id','end_id'], as_index=False).agg({'tripduration': 'sum', 'trip_id':'count', 'paidunits':'sum' })\n",
    "newdf = newdf.rename(index=str, columns={\"trip_id\": 'counts'})\n",
    "newdf['paidratio'] = newdf['paidunits']/newdf['counts']\n",
    "\n",
    "print(newdf.nlargest(20, 'counts'))\n",
    "print(\"The Most busy route is between #432 and #3263\")\n",
    "print(\"The Most busy station is #519\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% trip from top 3 station 2.018723301020378\n",
      "% trip to top 3 station 2.0587097110082855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(75223, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 3 Stations\n",
    "\n",
    "df_top_station = df_sub[df_sub['start_id'].isin(['432','3263','519'])]\n",
    "df_top_station1 = df_sub[df_sub['end_id'].isin(['432','3263','519'])]\n",
    "\n",
    "print('% trip from top 3 station', 100*(len(df_top_station)/len(df_sub)))\n",
    "print('% trip to top 3 station', 100*(len(df_top_station1)/len(df_sub)))\n",
    "\n",
    "df_top_station.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summ.to_csv('../data/df_summ_DV.csv', sep=',')\n",
    "df_sub.to_csv('../data/df_sub_DV.csv', sep=',')\n",
    "df_temp.to_csv('../data/df_temp_DV.csv', sep=',')\n",
    "trip_bymonth.to_csv('../data/df_trip_bymonth_DV.csv', sep=',')\n",
    "df_daily_trips.to_csv('../data/df_daily_trips_ML.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cust.to_csv('../data/df_cust_DV.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
